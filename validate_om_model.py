"""
OMæ¨¡å‹å…¨é‡æ¨ç†éªŒè¯ï¼ˆæ˜‡è…¾Atlas 200 DKï¼‰
æ ¸å¿ƒï¼šé¢„å¤„ç†ä¸¥æ ¼å¯¹é½è®­ç»ƒé€»è¾‘ + FP32ç²¾åº¦æ¨ç† + å…¨é‡æ ·æœ¬ç»Ÿè®¡
æ”¯æŒè®­ç»ƒé›†ã€æµ‹è¯•é›†å’Œå…¨é‡æ•°æ®çš„å‡†ç¡®ç‡è¯„ä¼°ï¼Œæœ€ç»ˆæ±‡æ€»å±•ç¤º
"""
import os
import sys
import ctypes
import traceback
import numpy as np
import time

# å¼ºåˆ¶é€‚é…æ˜‡è…¾21.0.3.1ç‰ˆæœ¬ACL
try:
    import acl
    # æ‰‹åŠ¨å®šä¹‰å¸¸é‡
    ACL_MEM_MALLOC_HUGE_FIRST = 0
    MEMCPY_HOST_TO_DEVICE = 1
    MEMCPY_DEVICE_TO_HOST = 2
except ImportError:
    print("é”™è¯¯ï¼šæœªæ‰¾åˆ°ACLæ¨¡å—ï¼Œè¯·é…ç½®ç¯å¢ƒå˜é‡")
    sys.exit(1)

# ===================== æ ¸å¿ƒé…ç½®ï¼ˆéœ€ä¸è®­ç»ƒ/è½¬æ¢å¯¹é½ï¼‰=====================
CONFIG = {
    'MODEL_PATH': './emotion_cnn.om',          # è½¬æ¢åçš„OMæ¨¡å‹è·¯å¾„
    'DATA_PATH': './fer2013.csv',  # æµ‹è¯•æ•°æ®è·¯å¾„
    'DEVICE_ID': 0,                            # NPUè®¾å¤‡ID
    'NUM_CLASSES': 7,                          # æƒ…ç»ªç±»åˆ«æ•°ï¼ˆ0-6ï¼‰
    'PROGRESS_STEP': 100,                      # è¿›åº¦æ˜¾ç¤ºæ­¥é•¿
    # é¢„å¤„ç†é…ç½®ï¼ˆå¿…é¡»ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼ï¼‰
    'PREPROCESS': {
        'mean': 0.0,       # è®­ç»ƒæ—¶çš„å‡å€¼ï¼ˆå¦‚æ— åˆ™0ï¼‰
        'std': 1.0,        # è®­ç»ƒæ—¶çš„æ ‡å‡†å·®ï¼ˆå¦‚æ— åˆ™1ï¼‰
        'scale': 1.0/255.0 # åƒç´ å½’ä¸€åŒ–ç³»æ•°ï¼ˆè®­ç»ƒæ—¶ç”¨/255åˆ™æ­¤å¤„ä¸º1/255ï¼‰
    },
    'EXPECT_INPUT_SIZE': 48*48*1*4  # é¢„æœŸè¾“å…¥å¤§å°ï¼š48x48x1(float32)=9216å­—èŠ‚
}

# å…¨å±€èµ„æºç®¡ç†ï¼ˆé¿å…é‡å¤åˆå§‹åŒ–ï¼‰
g_resources = {
    'context': None,
    'model_id': None,
    'model_desc': None,
    'input_buf': None,
    'output_buf': None,
    'input_size': 0,
    'output_size': 0
}

# æƒ…ç»ªæ ‡ç­¾æ˜ å°„ï¼ˆå¿…é¡»å’Œè®­ç»ƒä»£ç å®Œå…¨ä¸€è‡´ï¼ï¼‰
EMOTION_LABELS = {
    0: "ç”Ÿæ°”", 1: "åŒæ¶", 2: "ææƒ§",
    3: "å¼€å¿ƒ", 4: "ä¸­æ€§", 5: "æ‚²ä¼¤", 6: "æƒŠè®¶"
}


def stable_softmax(x):
    """æ•°å€¼ç¨³å®šçš„Softmaxï¼ˆé¿å…æº¢å‡ºï¼‰"""
    x_max = np.max(x)
    exp_x = np.exp(x - x_max)
    sum_exp_x = np.sum(exp_x)
    return exp_x / sum_exp_x if sum_exp_x != 0 else np.ones_like(x)/len(x)


def align_train_preprocess(pixel_array):
    """ä¸è®­ç»ƒå®Œå…¨å¯¹é½çš„é¢„å¤„ç†é€»è¾‘ï¼ˆæ ¸å¿ƒï¼ï¼‰"""
    img = pixel_array.astype(np.float32) * CONFIG['PREPROCESS']['scale']
    img = (img - CONFIG['PREPROCESS']['mean']) / CONFIG['PREPROCESS']['std']
    img = np.expand_dims(img, axis=0)  # batchç»´åº¦
    img = np.expand_dims(img, axis=0)  # é€šé“ç»´åº¦

    # è°ƒè¯•ä¿¡æ¯ï¼ˆéšæœºæ‰“å°ï¼‰
    if np.random.rand() < 0.001:
        print(f"\nã€é¢„å¤„ç†è°ƒè¯•ã€‘å‡å€¼ï¼š{np.mean(img):.4f}ï¼Œæœ€å¤§å€¼ï¼š{np.max(img):.4f}ï¼Œæœ€å°å€¼ï¼š{np.min(img):.4f}")
        print(f"ã€é¢„å¤„ç†è°ƒè¯•ã€‘å½¢çŠ¶ï¼š{img.shape}ï¼Œå­—èŠ‚æ•°ï¼š{img.nbytes}")

    return img


def safe_acl_init():
    """å®‰å…¨åˆå§‹åŒ–ACLå’ŒOMæ¨¡å‹ + è¾“å…¥å¤§å°éªŒè¯"""
    try:
        if not os.path.exists(CONFIG['MODEL_PATH']):
            raise FileNotFoundError(f"OMæ¨¡å‹ä¸å­˜åœ¨ï¼š{CONFIG['MODEL_PATH']}")

        # åˆå§‹åŒ–ACL
        ret = acl.init()
        ret = ret[-1] if isinstance(ret, (tuple, list)) else ret
        if ret != 0:
            raise RuntimeError(f"ACLåˆå§‹åŒ–å¤±è´¥ï¼Œé”™è¯¯ç ï¼š{ret}")

        # è®¾ç½®NPUè®¾å¤‡
        ret = acl.rt.set_device(CONFIG['DEVICE_ID'])
        ret = ret[-1] if isinstance(ret, (tuple, list)) else ret
        if ret != 0:
            raise RuntimeError(f"è®¾ç½®NPUè®¾å¤‡å¤±è´¥ï¼Œé”™è¯¯ç ï¼š{ret}")

        # åˆ›å»ºè®¾å¤‡ä¸Šä¸‹æ–‡
        create_ret = acl.rt.create_context(CONFIG['DEVICE_ID'])
        if isinstance(create_ret, (tuple, list)):
            g_resources['context'], ret = create_ret
        else:
            g_resources['context'] = create_ret
            ret = 0
        if ret != 0 or not g_resources['context']:
            raise RuntimeError(f"åˆ›å»ºä¸Šä¸‹æ–‡å¤±è´¥ï¼Œé”™è¯¯ç ï¼š{ret}")

        # åŠ è½½OMæ¨¡å‹
        load_ret = acl.mdl.load_from_file(CONFIG['MODEL_PATH'])
        if isinstance(load_ret, (tuple, list)):
            g_resources['model_id'], ret = load_ret
        else:
            g_resources['model_id'] = load_ret
            ret = 0
        if ret != 0 or not g_resources['model_id']:
            raise RuntimeError(f"åŠ è½½OMæ¨¡å‹å¤±è´¥ï¼Œé”™è¯¯ç ï¼š{ret}")

        # è·å–æ¨¡å‹æè¿°å’Œè¾“å…¥è¾“å‡ºå¤§å°
        g_resources['model_desc'] = acl.mdl.create_desc()
        acl.mdl.get_desc(g_resources['model_desc'], g_resources['model_id'])
        g_resources['input_size'] = acl.mdl.get_input_size_by_index(g_resources['model_desc'], 0)
        g_resources['output_size'] = acl.mdl.get_output_size_by_index(g_resources['model_desc'], 0)

        # è¾“å…¥å¤§å°éªŒè¯
        print(f"\nâš ï¸  è¾“å…¥å¤§å°éªŒè¯ï¼š")
        print(f"  æ¨¡å‹è¦æ±‚è¾“å…¥å¤§å°ï¼š{g_resources['input_size']} å­—èŠ‚")
        print(f"  é¢„æœŸè¾“å…¥å¤§å°ï¼ˆ48x48x1xfloat32ï¼‰ï¼š{CONFIG['EXPECT_INPUT_SIZE']} å­—èŠ‚")
        if g_resources['input_size'] != CONFIG['EXPECT_INPUT_SIZE']:
            print(f"âŒ è¾“å…¥å¤§å°ä¸åŒ¹é…ï¼å¯èƒ½æ˜¯ONNXå¯¼å‡º/ATCè½¬æ¢æ—¶è¾“å…¥å½¢çŠ¶é”™è¯¯")
            g_resources['input_size'] = CONFIG['EXPECT_INPUT_SIZE']

        # ç”³è¯·NPUè®¾å¤‡å†…å­˜
        malloc_ret = acl.rt.malloc(int(g_resources['input_size']), int(ACL_MEM_MALLOC_HUGE_FIRST))
        if isinstance(malloc_ret, (tuple, list)):
            g_resources['input_buf'], ret = malloc_ret
        else:
            g_resources['input_buf'] = malloc_ret
            ret = 0
        if ret != 0 or not g_resources['input_buf']:
            raise RuntimeError(f"ç”³è¯·è¾“å…¥å†…å­˜å¤±è´¥ï¼Œé”™è¯¯ç ï¼š{ret}")

        malloc_ret = acl.rt.malloc(int(g_resources['output_size']), int(ACL_MEM_MALLOC_HUGE_FIRST))
        if isinstance(malloc_ret, (tuple, list)):
            g_resources['output_buf'], ret = malloc_ret
        else:
            g_resources['output_buf'] = malloc_ret
            ret = 0
        if ret != 0 or not g_resources['output_buf']:
            raise RuntimeError(f"ç”³è¯·è¾“å‡ºå†…å­˜å¤±è´¥ï¼Œé”™è¯¯ç ï¼š{ret}")

        print(f"âœ… ACLåˆå§‹åŒ–æˆåŠŸ")
        print(f"  - æ¨¡å‹è¾“å…¥å¤§å°ï¼š{g_resources['input_size']} å­—èŠ‚")
        print(f"  - æ¨¡å‹è¾“å‡ºå¤§å°ï¼š{g_resources['output_size']} å­—èŠ‚")
        return True

    except Exception as e:
        print(f"âŒ ACLåˆå§‹åŒ–å¤±è´¥ï¼š{e}")
        traceback.print_exc()
        safe_acl_cleanup()
        return False


def om_model_infer(img_array):
    """OMæ¨¡å‹å•æ ·æœ¬æ¨ç†"""
    try:
        img_bytes = img_array.tobytes()
        actual_size = len(img_bytes)
        if actual_size > g_resources['input_size']:
            img_bytes = img_bytes[:g_resources['input_size']]
            print(f"âš ï¸  è¾“å…¥æ•°æ®è¿‡é•¿ï¼Œå·²æˆªæ–­è‡³{g_resources['input_size']}å­—èŠ‚")
        elif actual_size < g_resources['input_size']:
            print(f"âš ï¸  è¾“å…¥æ•°æ®è¿‡çŸ­ï¼ˆ{actual_size}å­—èŠ‚ < {g_resources['input_size']}å­—èŠ‚ï¼‰ï¼Œè¡¥é›¶å¯èƒ½å¯¼è‡´å¤±çœŸ")
            img_bytes = img_bytes.ljust(g_resources['input_size'], b'\x00')

        img_buffer = ctypes.create_string_buffer(img_bytes)
        src_ptr = ctypes.addressof(img_buffer)

        # ä¸»æœºâ†’NPUå†…å­˜æ‹·è´
        memcpy_ret = acl.rt.memcpy(
            int(g_resources['input_buf']),
            int(g_resources['input_size']),
            int(src_ptr),
            int(len(img_bytes)),
            int(MEMCPY_HOST_TO_DEVICE)
        )
        ret = memcpy_ret[-1] if isinstance(memcpy_ret, (tuple, list)) else memcpy_ret
        if ret != 0:
            raise RuntimeError(f"å†…å­˜æ‹·è´å¤±è´¥ï¼Œé”™è¯¯ç ï¼š{ret}")

        # åˆ›å»ºæ•°æ®é›†å’Œç¼“å†²åŒº
        dataset_in = acl.mdl.create_dataset()
        dataset_out = acl.mdl.create_dataset()

        # è¾“å…¥ç¼“å†²åŒº
        buf_ret = acl.create_data_buffer(int(g_resources['input_buf']), int(len(img_bytes)))
        input_buf_obj = buf_ret[0] if isinstance(buf_ret, (tuple, list)) else buf_ret
        if not input_buf_obj:
            raise RuntimeError("åˆ›å»ºè¾“å…¥ç¼“å†²åŒºå¤±è´¥")

        add_ret = acl.mdl.add_dataset_buffer(dataset_in, input_buf_obj)
        ret = add_ret[-1] if isinstance(add_ret, (tuple, list)) else add_ret
        if ret != 0:
            raise RuntimeError(f"æ·»åŠ è¾“å…¥ç¼“å†²åŒºå¤±è´¥ï¼Œé”™è¯¯ç ï¼š{ret}")

        # è¾“å‡ºç¼“å†²åŒº
        buf_ret = acl.create_data_buffer(int(g_resources['output_buf']), int(g_resources['output_size']))
        output_buf_obj = buf_ret[0] if isinstance(buf_ret, (tuple, list)) else buf_ret
        if not output_buf_obj:
            raise RuntimeError("åˆ›å»ºè¾“å‡ºç¼“å†²åŒºå¤±è´¥")

        add_ret = acl.mdl.add_dataset_buffer(dataset_out, output_buf_obj)
        ret = add_ret[-1] if isinstance(add_ret, (tuple, list)) else add_ret
        if ret != 0:
            raise RuntimeError(f"æ·»åŠ è¾“å‡ºç¼“å†²åŒºå¤±è´¥ï¼Œé”™è¯¯ç ï¼š{ret}")

        # æ‰§è¡ŒNPUæ¨ç†
        exec_ret = acl.mdl.execute(g_resources['model_id'], dataset_in, dataset_out)
        ret = exec_ret[-1] if isinstance(exec_ret, (tuple, list)) else exec_ret
        if ret != 0:
            raise RuntimeError(f"æ¨ç†æ‰§è¡Œå¤±è´¥ï¼Œé”™è¯¯ç ï¼š{ret}")

        # NPUâ†’ä¸»æœºå†…å­˜æ‹·è´
        out_buffer = ctypes.create_string_buffer(g_resources['output_size'])
        dst_ptr = ctypes.addressof(out_buffer)
        memcpy_ret = acl.rt.memcpy(
            int(dst_ptr),
            int(g_resources['output_size']),
            int(g_resources['output_buf']),
            int(g_resources['output_size']),
            int(MEMCPY_DEVICE_TO_HOST)
        )
        ret = memcpy_ret[-1] if isinstance(memcpy_ret, (tuple, list)) else memcpy_ret
        if ret != 0:
            raise RuntimeError(f"è¾“å‡ºæ‹·è´å¤±è´¥ï¼Œé”™è¯¯ç ï¼š{ret}")

        # è§£ææ¨ç†ç»“æœ
        output_data = np.frombuffer(out_buffer.raw, dtype=np.float32)
        output_data = output_data[:CONFIG['NUM_CLASSES']]
        pred_probs = stable_softmax(output_data)
        pred_label = np.argmax(pred_probs).item()

        # è°ƒè¯•ä¿¡æ¯ï¼ˆéšæœºæ‰“å°ï¼‰
        if np.random.rand() < 0.01:
            print(f"\nã€æ¨ç†è°ƒè¯•ã€‘è¾“å‡ºlogitsï¼š{output_data}")
            print(f"ã€æ¨ç†è°ƒè¯•ã€‘è¾“å‡ºæ¦‚ç‡ï¼š{pred_probs}")
            print(f"ã€æ¨ç†è°ƒè¯•ã€‘é¢„æµ‹æ ‡ç­¾ï¼š{pred_label}")

        # é‡Šæ”¾ä¸´æ—¶èµ„æº
        acl.destroy_data_buffer(input_buf_obj)
        acl.destroy_data_buffer(output_buf_obj)
        acl.mdl.destroy_dataset(dataset_in)
        acl.mdl.destroy_dataset(dataset_out)

        return pred_label

    except Exception as e:
        # å¼‚å¸¸å¤„ç†
        try:
            if 'dataset_in' in locals():
                acl.mdl.destroy_dataset(dataset_in)
            if 'dataset_out' in locals():
                acl.mdl.destroy_dataset(dataset_out)
            if 'input_buf_obj' in locals():
                acl.destroy_data_buffer(input_buf_obj)
            if 'output_buf_obj' in locals():
                acl.destroy_data_buffer(output_buf_obj)
        except:
            pass
        print(f"âŒ å•æ ·æœ¬æ¨ç†å¤±è´¥ï¼š{e}")
        return -1


def load_samples_by_type(data_type):
    """åŠ è½½æŒ‡å®šç±»å‹çš„æ ·æœ¬"""
    try:
        if not os.path.exists(CONFIG['DATA_PATH']):
            raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼š{CONFIG['DATA_PATH']}")

        samples = []
        label_dist = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0}

        import csv
        with open(CONFIG['DATA_PATH'], "r", encoding="utf-8") as f:
            reader = csv.reader(f)
            header = next(reader)
            emo_idx = header.index("emotion")
            pix_idx = header.index("pixels")
            use_idx = header.index("Usage") if "Usage" in header else -1

            for row in reader:
                if len(row) <= max(emo_idx, pix_idx):
                    continue

                # æ•°æ®ç±»å‹ç­›é€‰
                if use_idx >= 0:
                    usage = row[use_idx]
                    if data_type == 'train' and usage != "Training":
                        continue
                    if data_type == 'test' and usage not in ["PrivateTest", "PublicTest"]:
                        continue

                # è§£ææ•°æ®
                pixel_list = list(map(int, row[pix_idx].split()))
                pixel_array = np.array(pixel_list).reshape(48, 48)
                true_label = int(row[emo_idx])
                img_tensor = align_train_preprocess(pixel_array)
                samples.append((img_tensor, true_label, pixel_array))
                label_dist[true_label] += 1

        print(f"\nğŸ“Š {data_type}æ ·æœ¬åŠ è½½å®Œæˆ")
        print(f"  - æ€»æ ·æœ¬æ•°ï¼š{len(samples)}")
        print(f"  - æ ‡ç­¾åˆ†å¸ƒï¼š")
        for label, cnt in label_dist.items():
            print(f"    {EMOTION_LABELS[label]}({label})ï¼š{cnt} æ¡")

        # ç®€å•éªŒè¯
        if samples:
            test_idx = 0
            img_tensor, true_label, _ = samples[test_idx]
            om_pred = om_model_infer(img_tensor)
            print(f"\nğŸ” OMéªŒè¯ï¼ˆ{data_type}æ ·æœ¬{test_idx}ï¼‰ï¼š")
            print(f"  çœŸå®æ ‡ç­¾ï¼š{true_label}({EMOTION_LABELS[true_label]})")
            print(f"  OMé¢„æµ‹ï¼š{om_pred}({EMOTION_LABELS.get(om_pred, 'æœªçŸ¥')})")

        return samples

    except Exception as e:
        print(f"âŒ åŠ è½½{data_type}æ ·æœ¬å¤±è´¥ï¼š{e}")
        traceback.print_exc()
        return []


def evaluate_dataset(data_type):
    """è¯„ä¼°æŒ‡å®šç±»å‹æ•°æ®é›†ï¼Œè¿”å›è¯„ä¼°ç»“æœå­—å…¸"""
    samples = load_samples_by_type(data_type)
    if not samples:
        print(f"âš ï¸  æ²¡æœ‰å¯ç”¨çš„{data_type}æ ·æœ¬ï¼Œè·³è¿‡è¯„ä¼°")
        return None

    total = len(samples)
    correct = 0
    failed = 0
    label_stats = {i: {'total':0, 'correct':0} for i in range(7)}

    print(f"\nğŸš€ å¼€å§‹{data_type}æ•°æ®é›†æ¨ç†ï¼ˆå…±{total}æ¡æ ·æœ¬ï¼‰")
    start_time = time.time()

    for idx, (img_tensor, true_label, _) in enumerate(samples):
        pred_label = om_model_infer(img_tensor)
        label_stats[true_label]['total'] += 1
        if pred_label == -1:
            failed += 1
        else:
            if pred_label == true_label:
                correct += 1
                label_stats[true_label]['correct'] += 1

        # è¿›åº¦æ˜¾ç¤º
        if (idx + 1) % CONFIG['PROGRESS_STEP'] == 0:
            elapsed = time.time() - start_time
            speed = (idx + 1) / elapsed if elapsed > 0 else 0
            acc = 100.0 * correct / (idx + 1 - failed) if (idx + 1 - failed) > 0 else 0
            print(f"  è¿›åº¦ï¼š[{idx+1}/{total}] | å¤±è´¥ï¼š{failed} | å‡†ç¡®ç‡ï¼š{acc:.2f}% | é€Ÿåº¦ï¼š{speed:.2f}æ ·æœ¬/ç§’")

    # è®¡ç®—ç»“æœ
    elapsed_total = time.time() - start_time
    valid = total - failed
    overall_acc = 100.0 * correct / valid if valid > 0 else 0

    # æ‰“å°è¯¥æ•°æ®é›†çš„è¯¦ç»†ç»“æœï¼ˆä¿ç•™ä¸­é—´ä¿¡æ¯ï¼‰
    print(f"\nğŸ¯ {data_type}æ•°æ®é›†æ¨ç†ç»“æœæ±‡æ€»")
    print(f"  - æ€»è€—æ—¶ï¼š{elapsed_total:.2f} ç§’")
    print(f"  - å¹³å‡é€Ÿåº¦ï¼š{total/elapsed_total:.2f} æ ·æœ¬/ç§’")
    print(f"  - æ€»æ ·æœ¬ï¼š{total} | å¤±è´¥ï¼š{failed} | æœ‰æ•ˆï¼š{valid}")
    print(f"  - æ€»ä½“å‡†ç¡®ç‡ï¼š{overall_acc:.2f}%")
    print(f"  æŒ‰æ ‡ç­¾å‡†ç¡®ç‡ï¼š")
    for label in range(7):
        total_l = label_stats[label]['total']
        correct_l = label_stats[label]['correct']
        acc_l = 100.0 * correct_l / total_l if total_l > 0 else 0
        print(f"    {EMOTION_LABELS[label]}({label})ï¼š{correct_l}/{total_l} | {acc_l:.2f}%")
    print("--------------------------------------------------")

    # è¿”å›å…³é”®æŒ‡æ ‡ç”¨äºæœ€ç»ˆæ±‡æ€»
    return {
        'type': data_type,
        'total': total,
        'failed': failed,
        'valid': valid,
        'accuracy': overall_acc
    }


def safe_acl_cleanup():
    """å®‰å…¨é‡Šæ”¾ACLå’ŒNPUèµ„æº"""
    try:
        if g_resources['output_buf']:
            acl.rt.free(int(g_resources['output_buf']))
            g_resources['output_buf'] = None
        if g_resources['input_buf']:
            acl.rt.free(int(g_resources['input_buf']))
            g_resources['input_buf'] = None

        if g_resources['model_desc']:
            acl.mdl.destroy_desc(g_resources['model_desc'])
            g_resources['model_desc'] = None

        if g_resources['model_id']:
            unload_ret = acl.mdl.unload(int(g_resources['model_id']))
            ret = unload_ret[-1] if isinstance(unload_ret, (tuple, list)) else unload_ret
            if ret != 0:
                print(f"âš ï¸  å¸è½½æ¨¡å‹è­¦å‘Šï¼Œé”™è¯¯ç ï¼š{ret}")
            g_resources['model_id'] = None

        if g_resources['context']:
            acl.rt.destroy_context(g_resources['context'])
            g_resources['context'] = None

        acl.rt.reset_device(CONFIG['DEVICE_ID'])
        acl.finalize()
        print(f"\nâœ… ACLèµ„æºé‡Šæ”¾å®Œæˆ")

    except Exception as e:
        print(f"âš ï¸  èµ„æºé‡Šæ”¾è­¦å‘Šï¼š{e}")


if __name__ == '__main__':
    """ä¸»å‡½æ•°ï¼šåˆå§‹åŒ–â†’è¯„ä¼°â†’æ±‡æ€»æ‰“å°"""
    print("=====================================")
    print("  OMæ¨¡å‹æ¨ç†éªŒè¯ï¼ˆæ˜‡è…¾Atlas 200 DKï¼‰  ")
    print("=====================================")

    # 1. åˆå§‹åŒ–ACLå’Œæ¨¡å‹
    if not safe_acl_init():
        sys.exit(1)

    # 2. è¯„ä¼°å„æ•°æ®é›†å¹¶ä¿å­˜ç»“æœ
    eval_results = []
    eval_results.append(evaluate_dataset('train'))    # è®­ç»ƒé›†è¯„ä¼°
    eval_results.append(evaluate_dataset('test'))     # æµ‹è¯•é›†è¯„ä¼°
    eval_results.append(evaluate_dataset('all'))      # æ‰€æœ‰æ•°æ®è¯„ä¼°

    # 3. é‡Šæ”¾èµ„æº
    safe_acl_cleanup()

    # 4. æœ€ç»ˆæ±‡æ€»æ‰“å°ä¸‰ç§å‡†ç¡®ç‡
    print("\n=====================================")
    print("          å‡†ç¡®ç‡æ±‡æ€»å¯¹æ¯”           ")
    print("=====================================")
    for result in eval_results:
        if result:  # è·³è¿‡ç©ºç»“æœï¼ˆæ— æ ·æœ¬çš„æƒ…å†µï¼‰
            print(f"{result['type']}é›†ï¼š")
            print(f"  æ€»æ ·æœ¬æ•°ï¼š{result['total']} | å¤±è´¥ï¼š{result['failed']} | æœ‰æ•ˆæ ·æœ¬ï¼š{result['valid']}")
            print(f"  å‡†ç¡®ç‡ï¼š{result['accuracy']:.2f}%")
            print("-------------------------------------")

    print("\nğŸ‰ æ‰€æœ‰æ•°æ®é›†æ¨ç†éªŒè¯å®Œæˆï¼")